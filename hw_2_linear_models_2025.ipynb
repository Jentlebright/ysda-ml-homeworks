{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лабораторная работа 2. Линейные модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Некоторые задачи в этом ноутбуке надо будет сдавать в [контест](https://contest.yandex.ru/contest/68191/enter). Когда сдаете туда код, не забудьте сверху прописать все нужные импорты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Мы рассчитываем, что перед тем, как садиться за этот ноутбук, вы прослушали лекции про МНК, регрессию и регуляризацию или прочитали часть про регрессию главы \"Линейные модели\" ШАДовского учебника по ML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнём с загрузки необходимых библиотек и функций.\n",
    "Параметр `seed` будет использоваться далее для инициализации генератора случайных чисел из библиотеки `numpy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Optional, List\n",
    "\n",
    "import sklearn.base\n",
    "\n",
    "seed = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом ноутбуке мы будем практиковаться на датасете [\"The Ames Iowa Housing Data\"](https://www.openml.org/d/41211). Здесь собраны описания и цены жилья в городе Эймс, штат Айова. Мы будем решать задачу предсказания цены (`Sale_Price`) по всем остальным признакам.\n",
    "\n",
    "И начнём мы, конечно, с того, что внимательно посмотрим на датасет: какие там есть объекты и какие признаки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Uncomment the line below to download data and install necessary packages\n",
    "## Maybe won't work on Windows :(\n",
    "\n",
    "# !pip install numpy pandas sklearn matplotlib\n",
    "# !curl https://api.openml.org/data/get_csv/20649135/file2ed11cebe25.arff > data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MS_SubClass</th>\n",
       "      <th>MS_Zoning</th>\n",
       "      <th>Lot_Frontage</th>\n",
       "      <th>Lot_Area</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>Lot_Shape</th>\n",
       "      <th>Land_Contour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>Lot_Config</th>\n",
       "      <th>...</th>\n",
       "      <th>Fence</th>\n",
       "      <th>Misc_Feature</th>\n",
       "      <th>Misc_Val</th>\n",
       "      <th>Mo_Sold</th>\n",
       "      <th>Year_Sold</th>\n",
       "      <th>Sale_Type</th>\n",
       "      <th>Sale_Condition</th>\n",
       "      <th>Sale_Price</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>One_Story_1946_and_Newer_All_Styles</td>\n",
       "      <td>Residential_High_Density</td>\n",
       "      <td>60</td>\n",
       "      <td>8400</td>\n",
       "      <td>Pave</td>\n",
       "      <td>No_Alley_Access</td>\n",
       "      <td>Regular</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>No_Fence</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>82000</td>\n",
       "      <td>-93.679075</td>\n",
       "      <td>42.036538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1859</th>\n",
       "      <td>One_Story_1946_and_Newer_All_Styles</td>\n",
       "      <td>Residential_Low_Density</td>\n",
       "      <td>80</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>No_Alley_Access</td>\n",
       "      <td>Regular</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>No_Fence</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "      <td>-93.645544</td>\n",
       "      <td>42.042961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2569</th>\n",
       "      <td>One_Story_1946_and_Newer_All_Styles</td>\n",
       "      <td>Residential_Low_Density</td>\n",
       "      <td>75</td>\n",
       "      <td>9000</td>\n",
       "      <td>Pave</td>\n",
       "      <td>No_Alley_Access</td>\n",
       "      <td>Regular</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>Good_Wood</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Family</td>\n",
       "      <td>118000</td>\n",
       "      <td>-93.618115</td>\n",
       "      <td>42.042297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1343</th>\n",
       "      <td>One_Story_1945_and_Older</td>\n",
       "      <td>Residential_Medium_Density</td>\n",
       "      <td>0</td>\n",
       "      <td>6120</td>\n",
       "      <td>Pave</td>\n",
       "      <td>No_Alley_Access</td>\n",
       "      <td>Regular</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>No_Fence</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>81300</td>\n",
       "      <td>-93.622566</td>\n",
       "      <td>42.032476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1147</th>\n",
       "      <td>One_Story_PUD_1946_and_Newer</td>\n",
       "      <td>Residential_Low_Density</td>\n",
       "      <td>50</td>\n",
       "      <td>8012</td>\n",
       "      <td>Pave</td>\n",
       "      <td>No_Alley_Access</td>\n",
       "      <td>Regular</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>No_Fence</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>193000</td>\n",
       "      <td>-93.686428</td>\n",
       "      <td>42.036501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1854</th>\n",
       "      <td>One_Story_1946_and_Newer_All_Styles</td>\n",
       "      <td>Residential_Low_Density</td>\n",
       "      <td>80</td>\n",
       "      <td>12000</td>\n",
       "      <td>Pave</td>\n",
       "      <td>No_Alley_Access</td>\n",
       "      <td>Regular</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>No_Fence</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>255000</td>\n",
       "      <td>-93.645798</td>\n",
       "      <td>42.044762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1083</th>\n",
       "      <td>One_Story_1946_and_Newer_All_Styles</td>\n",
       "      <td>Residential_Low_Density</td>\n",
       "      <td>43</td>\n",
       "      <td>3182</td>\n",
       "      <td>Pave</td>\n",
       "      <td>No_Alley_Access</td>\n",
       "      <td>Regular</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>No_Fence</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>159895</td>\n",
       "      <td>-93.643039</td>\n",
       "      <td>42.062004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>One_Story_PUD_1946_and_Newer</td>\n",
       "      <td>Residential_Low_Density</td>\n",
       "      <td>34</td>\n",
       "      <td>5063</td>\n",
       "      <td>Pave</td>\n",
       "      <td>No_Alley_Access</td>\n",
       "      <td>Regular</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>No_Fence</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2009</td>\n",
       "      <td>ConLw</td>\n",
       "      <td>Normal</td>\n",
       "      <td>207500</td>\n",
       "      <td>-93.649649</td>\n",
       "      <td>42.058368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>Two_Family_conversion_All_Styles_and_Ages</td>\n",
       "      <td>Residential_Medium_Density</td>\n",
       "      <td>60</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Gravel</td>\n",
       "      <td>Regular</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>No_Fence</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>130000</td>\n",
       "      <td>-93.617386</td>\n",
       "      <td>42.028287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>One_Story_1946_and_Newer_All_Styles</td>\n",
       "      <td>Residential_Low_Density</td>\n",
       "      <td>75</td>\n",
       "      <td>7500</td>\n",
       "      <td>Pave</td>\n",
       "      <td>No_Alley_Access</td>\n",
       "      <td>Regular</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>Good_Privacy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>154000</td>\n",
       "      <td>-93.605969</td>\n",
       "      <td>42.035940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1580</th>\n",
       "      <td>One_Story_1946_and_Newer_All_Styles</td>\n",
       "      <td>Residential_Low_Density</td>\n",
       "      <td>47</td>\n",
       "      <td>12416</td>\n",
       "      <td>Pave</td>\n",
       "      <td>No_Alley_Access</td>\n",
       "      <td>Slightly_Irregular</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>No_Fence</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>184000</td>\n",
       "      <td>-93.646054</td>\n",
       "      <td>41.999575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1134</th>\n",
       "      <td>One_Story_1946_and_Newer_All_Styles</td>\n",
       "      <td>Residential_Low_Density</td>\n",
       "      <td>63</td>\n",
       "      <td>13072</td>\n",
       "      <td>Pave</td>\n",
       "      <td>No_Alley_Access</td>\n",
       "      <td>Regular</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>No_Fence</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>146000</td>\n",
       "      <td>-93.691836</td>\n",
       "      <td>42.037918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>One_and_Half_Story_Finished_All_Ages</td>\n",
       "      <td>Residential_Medium_Density</td>\n",
       "      <td>55</td>\n",
       "      <td>8674</td>\n",
       "      <td>Pave</td>\n",
       "      <td>No_Alley_Access</td>\n",
       "      <td>Regular</td>\n",
       "      <td>HLS</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>No_Fence</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>128250</td>\n",
       "      <td>-93.626272</td>\n",
       "      <td>42.034339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2546</th>\n",
       "      <td>One_Story_1946_and_Newer_All_Styles</td>\n",
       "      <td>Residential_Low_Density</td>\n",
       "      <td>0</td>\n",
       "      <td>10368</td>\n",
       "      <td>Pave</td>\n",
       "      <td>No_Alley_Access</td>\n",
       "      <td>Slightly_Irregular</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>CulDSac</td>\n",
       "      <td>...</td>\n",
       "      <td>No_Fence</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>167000</td>\n",
       "      <td>-93.627065</td>\n",
       "      <td>42.041020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1356</th>\n",
       "      <td>Two_Story_1946_and_Newer</td>\n",
       "      <td>Residential_Medium_Density</td>\n",
       "      <td>57</td>\n",
       "      <td>8094</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Gravel</td>\n",
       "      <td>Regular</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>Minimum_Privacy</td>\n",
       "      <td>Shed</td>\n",
       "      <td>1000</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>160000</td>\n",
       "      <td>-93.621676</td>\n",
       "      <td>42.029030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2756</th>\n",
       "      <td>Two_Story_1946_and_Newer</td>\n",
       "      <td>Residential_Low_Density</td>\n",
       "      <td>73</td>\n",
       "      <td>8760</td>\n",
       "      <td>Pave</td>\n",
       "      <td>No_Alley_Access</td>\n",
       "      <td>Regular</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>No_Fence</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2006</td>\n",
       "      <td>New</td>\n",
       "      <td>Partial</td>\n",
       "      <td>239799</td>\n",
       "      <td>-93.688924</td>\n",
       "      <td>42.025194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2701</th>\n",
       "      <td>Split_or_Multilevel</td>\n",
       "      <td>Residential_Low_Density</td>\n",
       "      <td>92</td>\n",
       "      <td>6930</td>\n",
       "      <td>Pave</td>\n",
       "      <td>No_Alley_Access</td>\n",
       "      <td>Slightly_Irregular</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>No_Fence</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>130000</td>\n",
       "      <td>-93.657834</td>\n",
       "      <td>42.033145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1886</th>\n",
       "      <td>One_Story_1946_and_Newer_All_Styles</td>\n",
       "      <td>Residential_Low_Density</td>\n",
       "      <td>0</td>\n",
       "      <td>8339</td>\n",
       "      <td>Pave</td>\n",
       "      <td>No_Alley_Access</td>\n",
       "      <td>Slightly_Irregular</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>Minimum_Privacy</td>\n",
       "      <td>Shed</td>\n",
       "      <td>1200</td>\n",
       "      <td>7</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>106500</td>\n",
       "      <td>-93.622320</td>\n",
       "      <td>42.042479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2737</th>\n",
       "      <td>Two_and_Half_Story_All_Ages</td>\n",
       "      <td>Residential_Low_Density</td>\n",
       "      <td>60</td>\n",
       "      <td>19800</td>\n",
       "      <td>Pave</td>\n",
       "      <td>No_Alley_Access</td>\n",
       "      <td>Regular</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>No_Fence</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>415000</td>\n",
       "      <td>-93.660664</td>\n",
       "      <td>42.028191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282</th>\n",
       "      <td>One_Story_1946_and_Newer_All_Styles</td>\n",
       "      <td>Residential_Low_Density</td>\n",
       "      <td>69</td>\n",
       "      <td>7590</td>\n",
       "      <td>Pave</td>\n",
       "      <td>No_Alley_Access</td>\n",
       "      <td>Regular</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>No_Fence</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2008</td>\n",
       "      <td>COD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>136870</td>\n",
       "      <td>-93.603702</td>\n",
       "      <td>42.035724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    MS_SubClass                   MS_Zoning  \\\n",
       "552         One_Story_1946_and_Newer_All_Styles    Residential_High_Density   \n",
       "1859        One_Story_1946_and_Newer_All_Styles     Residential_Low_Density   \n",
       "2569        One_Story_1946_and_Newer_All_Styles     Residential_Low_Density   \n",
       "1343                   One_Story_1945_and_Older  Residential_Medium_Density   \n",
       "1147               One_Story_PUD_1946_and_Newer     Residential_Low_Density   \n",
       "1854        One_Story_1946_and_Newer_All_Styles     Residential_Low_Density   \n",
       "1083        One_Story_1946_and_Newer_All_Styles     Residential_Low_Density   \n",
       "482                One_Story_PUD_1946_and_Newer     Residential_Low_Density   \n",
       "1312  Two_Family_conversion_All_Styles_and_Ages  Residential_Medium_Density   \n",
       "162         One_Story_1946_and_Newer_All_Styles     Residential_Low_Density   \n",
       "1580        One_Story_1946_and_Newer_All_Styles     Residential_Low_Density   \n",
       "1134        One_Story_1946_and_Newer_All_Styles     Residential_Low_Density   \n",
       "2006       One_and_Half_Story_Finished_All_Ages  Residential_Medium_Density   \n",
       "2546        One_Story_1946_and_Newer_All_Styles     Residential_Low_Density   \n",
       "1356                   Two_Story_1946_and_Newer  Residential_Medium_Density   \n",
       "2756                   Two_Story_1946_and_Newer     Residential_Low_Density   \n",
       "2701                        Split_or_Multilevel     Residential_Low_Density   \n",
       "1886        One_Story_1946_and_Newer_All_Styles     Residential_Low_Density   \n",
       "2737                Two_and_Half_Story_All_Ages     Residential_Low_Density   \n",
       "1282        One_Story_1946_and_Newer_All_Styles     Residential_Low_Density   \n",
       "\n",
       "      Lot_Frontage  Lot_Area Street            Alley           Lot_Shape  \\\n",
       "552             60      8400   Pave  No_Alley_Access             Regular   \n",
       "1859            80      9600   Pave  No_Alley_Access             Regular   \n",
       "2569            75      9000   Pave  No_Alley_Access             Regular   \n",
       "1343             0      6120   Pave  No_Alley_Access             Regular   \n",
       "1147            50      8012   Pave  No_Alley_Access             Regular   \n",
       "1854            80     12000   Pave  No_Alley_Access             Regular   \n",
       "1083            43      3182   Pave  No_Alley_Access             Regular   \n",
       "482             34      5063   Pave  No_Alley_Access             Regular   \n",
       "1312            60      9600   Pave           Gravel             Regular   \n",
       "162             75      7500   Pave  No_Alley_Access             Regular   \n",
       "1580            47     12416   Pave  No_Alley_Access  Slightly_Irregular   \n",
       "1134            63     13072   Pave  No_Alley_Access             Regular   \n",
       "2006            55      8674   Pave  No_Alley_Access             Regular   \n",
       "2546             0     10368   Pave  No_Alley_Access  Slightly_Irregular   \n",
       "1356            57      8094   Pave           Gravel             Regular   \n",
       "2756            73      8760   Pave  No_Alley_Access             Regular   \n",
       "2701            92      6930   Pave  No_Alley_Access  Slightly_Irregular   \n",
       "1886             0      8339   Pave  No_Alley_Access  Slightly_Irregular   \n",
       "2737            60     19800   Pave  No_Alley_Access             Regular   \n",
       "1282            69      7590   Pave  No_Alley_Access             Regular   \n",
       "\n",
       "     Land_Contour Utilities Lot_Config  ...            Fence Misc_Feature  \\\n",
       "552           Lvl    AllPub     Inside  ...         No_Fence          NaN   \n",
       "1859          Lvl    AllPub        FR2  ...         No_Fence          NaN   \n",
       "2569          Lvl    AllPub     Inside  ...        Good_Wood          NaN   \n",
       "1343          Lvl    AllPub     Inside  ...         No_Fence          NaN   \n",
       "1147          Lvl    AllPub     Inside  ...         No_Fence          NaN   \n",
       "1854          Lvl    AllPub     Inside  ...         No_Fence          NaN   \n",
       "1083          Lvl    AllPub     Inside  ...         No_Fence          NaN   \n",
       "482           Lvl    AllPub     Inside  ...         No_Fence          NaN   \n",
       "1312          Lvl    AllPub     Inside  ...         No_Fence          NaN   \n",
       "162           Lvl    AllPub     Inside  ...     Good_Privacy          NaN   \n",
       "1580          Lvl    AllPub     Inside  ...         No_Fence          NaN   \n",
       "1134          Lvl    AllPub     Inside  ...         No_Fence          NaN   \n",
       "2006          HLS    AllPub     Inside  ...         No_Fence          NaN   \n",
       "2546          Lvl    AllPub    CulDSac  ...         No_Fence          NaN   \n",
       "1356          Lvl    AllPub     Inside  ...  Minimum_Privacy         Shed   \n",
       "2756          Lvl    AllPub     Inside  ...         No_Fence          NaN   \n",
       "2701          Lvl    AllPub     Inside  ...         No_Fence          NaN   \n",
       "1886          Lvl    AllPub     Inside  ...  Minimum_Privacy         Shed   \n",
       "2737          Lvl    AllPub     Inside  ...         No_Fence          NaN   \n",
       "1282          Lvl    AllPub     Inside  ...         No_Fence          NaN   \n",
       "\n",
       "     Misc_Val Mo_Sold Year_Sold Sale_Type Sale_Condition Sale_Price  \\\n",
       "552         0       9      2009       WD          Normal      82000   \n",
       "1859        0       5      2007       WD          Normal     181500   \n",
       "2569        0       6      2006       WD          Family     118000   \n",
       "1343        0       6      2008       WD          Normal      81300   \n",
       "1147        0       7      2008       WD          Normal     193000   \n",
       "1854        0       3      2007       WD          Normal     255000   \n",
       "1083        0       3      2008       WD          Normal     159895   \n",
       "482         0       4      2009     ConLw         Normal     207500   \n",
       "1312        0       4      2008       WD          Normal     130000   \n",
       "162         0       5      2010       WD          Normal     154000   \n",
       "1580        0      11      2008       WD          Normal     184000   \n",
       "1134        0       6      2008       WD          Normal     146000   \n",
       "2006        0       3      2007       WD          Normal     128250   \n",
       "2546        0       4      2006       WD          Normal     167000   \n",
       "1356     1000       9      2008       WD          Normal     160000   \n",
       "2756        0       8      2006       New        Partial     239799   \n",
       "2701        0       7      2006       WD         Abnorml     130000   \n",
       "1886     1200       7      2007       WD          Normal     106500   \n",
       "2737        0      12      2006       WD          Normal     415000   \n",
       "1282        0       5      2008       COD         Normal     136870   \n",
       "\n",
       "      Longitude   Latitude  \n",
       "552  -93.679075  42.036538  \n",
       "1859 -93.645544  42.042961  \n",
       "2569 -93.618115  42.042297  \n",
       "1343 -93.622566  42.032476  \n",
       "1147 -93.686428  42.036501  \n",
       "1854 -93.645798  42.044762  \n",
       "1083 -93.643039  42.062004  \n",
       "482  -93.649649  42.058368  \n",
       "1312 -93.617386  42.028287  \n",
       "162  -93.605969  42.035940  \n",
       "1580 -93.646054  41.999575  \n",
       "1134 -93.691836  42.037918  \n",
       "2006 -93.626272  42.034339  \n",
       "2546 -93.627065  42.041020  \n",
       "1356 -93.621676  42.029030  \n",
       "2756 -93.688924  42.025194  \n",
       "2701 -93.657834  42.033145  \n",
       "1886 -93.622320  42.042479  \n",
       "2737 -93.660664  42.028191  \n",
       "1282 -93.603702  42.035724  \n",
       "\n",
       "[20 rows x 81 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./data.csv')\n",
    "\n",
    "data.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2930 entries, 0 to 2929\n",
      "Data columns (total 81 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   MS_SubClass         2930 non-null   object \n",
      " 1   MS_Zoning           2930 non-null   object \n",
      " 2   Lot_Frontage        2930 non-null   int64  \n",
      " 3   Lot_Area            2930 non-null   int64  \n",
      " 4   Street              2930 non-null   object \n",
      " 5   Alley               2930 non-null   object \n",
      " 6   Lot_Shape           2930 non-null   object \n",
      " 7   Land_Contour        2930 non-null   object \n",
      " 8   Utilities           2930 non-null   object \n",
      " 9   Lot_Config          2930 non-null   object \n",
      " 10  Land_Slope          2930 non-null   object \n",
      " 11  Neighborhood        2930 non-null   object \n",
      " 12  Condition_1         2930 non-null   object \n",
      " 13  Condition_2         2930 non-null   object \n",
      " 14  Bldg_Type           2930 non-null   object \n",
      " 15  House_Style         2930 non-null   object \n",
      " 16  Overall_Qual        2930 non-null   object \n",
      " 17  Overall_Cond        2930 non-null   object \n",
      " 18  Year_Built          2930 non-null   int64  \n",
      " 19  Year_Remod_Add      2930 non-null   int64  \n",
      " 20  Roof_Style          2930 non-null   object \n",
      " 21  Roof_Matl           2930 non-null   object \n",
      " 22  Exterior_1st        2930 non-null   object \n",
      " 23  Exterior_2nd        2930 non-null   object \n",
      " 24  Mas_Vnr_Type        1155 non-null   object \n",
      " 25  Mas_Vnr_Area        2930 non-null   int64  \n",
      " 26  Exter_Qual          2930 non-null   object \n",
      " 27  Exter_Cond          2930 non-null   object \n",
      " 28  Foundation          2930 non-null   object \n",
      " 29  Bsmt_Qual           2930 non-null   object \n",
      " 30  Bsmt_Cond           2930 non-null   object \n",
      " 31  Bsmt_Exposure       2930 non-null   object \n",
      " 32  BsmtFin_Type_1      2930 non-null   object \n",
      " 33  BsmtFin_SF_1        2930 non-null   int64  \n",
      " 34  BsmtFin_Type_2      2930 non-null   object \n",
      " 35  BsmtFin_SF_2        2930 non-null   int64  \n",
      " 36  Bsmt_Unf_SF         2930 non-null   int64  \n",
      " 37  Total_Bsmt_SF       2930 non-null   int64  \n",
      " 38  Heating             2930 non-null   object \n",
      " 39  Heating_QC          2930 non-null   object \n",
      " 40  Central_Air         2930 non-null   object \n",
      " 41  Electrical          2930 non-null   object \n",
      " 42  First_Flr_SF        2930 non-null   int64  \n",
      " 43  Second_Flr_SF       2930 non-null   int64  \n",
      " 44  Low_Qual_Fin_SF     2930 non-null   int64  \n",
      " 45  Gr_Liv_Area         2930 non-null   int64  \n",
      " 46  Bsmt_Full_Bath      2930 non-null   int64  \n",
      " 47  Bsmt_Half_Bath      2930 non-null   int64  \n",
      " 48  Full_Bath           2930 non-null   int64  \n",
      " 49  Half_Bath           2930 non-null   int64  \n",
      " 50  Bedroom_AbvGr       2930 non-null   int64  \n",
      " 51  Kitchen_AbvGr       2930 non-null   int64  \n",
      " 52  Kitchen_Qual        2930 non-null   object \n",
      " 53  TotRms_AbvGrd       2930 non-null   int64  \n",
      " 54  Functional          2930 non-null   object \n",
      " 55  Fireplaces          2930 non-null   int64  \n",
      " 56  Fireplace_Qu        2930 non-null   object \n",
      " 57  Garage_Type         2930 non-null   object \n",
      " 58  Garage_Finish       2930 non-null   object \n",
      " 59  Garage_Cars         2930 non-null   int64  \n",
      " 60  Garage_Area         2930 non-null   int64  \n",
      " 61  Garage_Qual         2930 non-null   object \n",
      " 62  Garage_Cond         2930 non-null   object \n",
      " 63  Paved_Drive         2930 non-null   object \n",
      " 64  Wood_Deck_SF        2930 non-null   int64  \n",
      " 65  Open_Porch_SF       2930 non-null   int64  \n",
      " 66  Enclosed_Porch      2930 non-null   int64  \n",
      " 67  Three_season_porch  2930 non-null   int64  \n",
      " 68  Screen_Porch        2930 non-null   int64  \n",
      " 69  Pool_Area           2930 non-null   int64  \n",
      " 70  Pool_QC             2930 non-null   object \n",
      " 71  Fence               2930 non-null   object \n",
      " 72  Misc_Feature        106 non-null    object \n",
      " 73  Misc_Val            2930 non-null   int64  \n",
      " 74  Mo_Sold             2930 non-null   int64  \n",
      " 75  Year_Sold           2930 non-null   int64  \n",
      " 76  Sale_Type           2930 non-null   object \n",
      " 77  Sale_Condition      2930 non-null   object \n",
      " 78  Sale_Price          2930 non-null   int64  \n",
      " 79  Longitude           2930 non-null   float64\n",
      " 80  Latitude            2930 non-null   float64\n",
      "dtypes: float64(2), int64(33), object(46)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разобьём данные на обучающую и тестовую выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train : (2344, 80) (2344,)\n",
      "Test : (586, 80) (586,)\n"
     ]
    }
   ],
   "source": [
    "target_column = \"Sale_Price\"\n",
    "np.random.seed(seed)\n",
    "\n",
    "test_size = 0.2\n",
    "data_train, data_test, Y_train, Y_test = train_test_split(\n",
    "    data[data.columns.drop(\"Sale_Price\")],\n",
    "    np.array(data[\"Sale_Price\"]),\n",
    "    test_size=test_size,\n",
    "    random_state=seed)\n",
    "\n",
    "print(f\"Train : {data_train.shape} {Y_train.shape}\")\n",
    "print(f\"Test : {data_test.shape} {Y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Среди признаков нам встретятся как вещественные, так и категориальные. Пока что выделим в качестве категориальных те, значениями которых являются не числа, а какие-то другие сущности. Но имейте в виду, что численные с виду признаки тоже могут быть категориальными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuous : 34, Categorical : 46\n"
     ]
    }
   ],
   "source": [
    "continuous_columns = [key for key in data.keys() if data[key].dtype in (\"int64\", \"float64\")]\n",
    "categorical_columns = [key for key in data.keys() if data[key].dtype == \"object\"]\n",
    "\n",
    "continuous_columns.remove(target_column)\n",
    "\n",
    "print(f\"Continuous : {len(continuous_columns)}, Categorical : {len(categorical_columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на заголовки признаков. В целом, многие названия вполне говорящие, и можно догадаться, что стоит за этими признаками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lot_Frontage',\n",
       " 'Lot_Area',\n",
       " 'Year_Built',\n",
       " 'Year_Remod_Add',\n",
       " 'Mas_Vnr_Area',\n",
       " 'BsmtFin_SF_1',\n",
       " 'BsmtFin_SF_2',\n",
       " 'Bsmt_Unf_SF',\n",
       " 'Total_Bsmt_SF',\n",
       " 'First_Flr_SF',\n",
       " 'Second_Flr_SF',\n",
       " 'Low_Qual_Fin_SF',\n",
       " 'Gr_Liv_Area',\n",
       " 'Bsmt_Full_Bath',\n",
       " 'Bsmt_Half_Bath',\n",
       " 'Full_Bath',\n",
       " 'Half_Bath',\n",
       " 'Bedroom_AbvGr',\n",
       " 'Kitchen_AbvGr',\n",
       " 'TotRms_AbvGrd',\n",
       " 'Fireplaces',\n",
       " 'Garage_Cars',\n",
       " 'Garage_Area',\n",
       " 'Wood_Deck_SF',\n",
       " 'Open_Porch_SF',\n",
       " 'Enclosed_Porch',\n",
       " 'Three_season_porch',\n",
       " 'Screen_Porch',\n",
       " 'Pool_Area',\n",
       " 'Misc_Val',\n",
       " 'Mo_Sold',\n",
       " 'Year_Sold',\n",
       " 'Longitude',\n",
       " 'Latitude']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continuous_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Одна из целей этого ноутбука — познакомить вас с fit-predict (fit-transform) интерфейсом, типичным для многих реализаций моделей машинного обучения и для различных инструментов работы с данными.\n",
    "\n",
    "Множество фреймворков машинного обучения (например, scikit-learn, CatBoost) содержат в себе модели, которые описаны в виде классов, у которых есть два ключевых метода: `fit` и `predict` (`transform`). Давайте разберёмся, что делают эти методы.\n",
    "\n",
    "* **`fit`** — метод для обучения модели. Он получает на входе данные и таргеты для обучения, после чего обновляет состояние класса. После использования метода fit считается, что объект класса готов к использованию. Внутри этого метода может быть что угодно: обучение модели, подбор гиперпараметров, подсчет статистик и т. д.\n",
    "\n",
    "* **`predict`** — метод для предсказания , обученного с помощью `fit`. В задаче регрессии это оценка параметра, в задаче классификации предсказанный класс.\n",
    "\n",
    "* **`transform`** — стилистический синоним `predict`, но используется в классах, которые реализуют преобразования данных, например, масштабирование признаков или кодирование категориальных фичей.\n",
    "\n",
    "* **`fit_transform`** — метод который учится на данных, а потом их же преобразовывает."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Базовая предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отметим два важных свойства линейной регрессии:\n",
    "\n",
    "- строго говоря, она умеет работать только с вещественными признаками\n",
    "- если признаки имеют разный масштаб, то регуляризация может штрафовать коэффициенты за несоответствие.\n",
    "\n",
    "Первое соображение заставляет придумывать способы борьбы с категориальными признаками, и мы начнём с самого простого: проигнорируем их.\n",
    "Второе соображение приводит к необходимости приводить признаки к одному масштабу (\"нормализовать фичи\"). В `sklearn` для этого есть два основных класса:\n",
    "\n",
    "- [sklearn.preprocessing.StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) &mdash; в каждой колонке вычитает среднее и делит на стандартное отклонение.\n",
    "- [sklearn.preprocessing.MinMaxScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html) &mdash; в каждой колонке вычитает минимальное значение и делит на разницу между минимальным и максимальным.\n",
    "\n",
    "Применяются они в соответствии с описанной выше философией. Например:\n",
    "\n",
    "```\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "```\n",
    "\n",
    "Обратите внимание, что scaler настраивается на обучающей выборке (именно по ней вычисляются среднее и стандартное отклонение), а к тестовой он применяется с уже подсчитанными статистиками.\n",
    "\n",
    "**Вопрос**. А зачем? Почему бы не нормировать отдельно обучающую и тестовую выборку? Почему бы не настроить наш scaler на объединении двух выборок? Ведь благодаря большему количеству данных мы бы настроили его точнее!\n",
    "<p>\n",
    "<details>\n",
    "  <summary>Кликните, чтобы узнать ответ</summary>\n",
    "\n",
    "Если мы по-разному отнормируем обучающую и тестовую выборки, то нам будет весьма сложно применять модель, обученную на одной из них, к другой. Это просто не будет иметь физического смысла.\n",
    "\n",
    "Настраивать что-либо на тестовой выборке — это очень плохая идея. Тестовая выборка должна быть неким независимым мерилом качества наших усилий по предсказанию, а если мы разрешим информации о распределении признаков в тестовой выборке \"протечь\" в процесс обучения, то мы эту независимость испортим.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import TransformerMixin\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from typing import Optional, List\n",
    "import sklearn.base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, мы решили делать преобразование данных, которое состоит в:\n",
    "\n",
    "- сохранении лишь непрерывных фичей;\n",
    "- нормализации этих фичей (давайте остановимся на [sklearn.preprocessing.StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html))\n",
    "\n",
    "В этом пункте вам нужно будет сделать класс такой предобработки данных, причём оформим мы его в виде класса с интерфейсом fit-transform.\n",
    "\n",
    "Несколько важных соображений:\n",
    "\n",
    "1. В прошлой лабораторной метод fit у нас ничего не возвращал, но правильнее сделать так, чтобы метод fit возвращал сам класс. В частности, это позволит нам писать model = model.fit().\n",
    "\n",
    "2. Первоначальный анализ данных удобно делать, когда они лежат в pd.DataFrame, т к у этого класса много методов, которые малым количеством телодвижений позволяют считать статистики и строить графики. Модели же проще учить, когда данные лежат в np.array, потому большое количество библиотек, где реализованы методы машинного обучения совместимы именно с numpy. Поэтому сделайте так, чтобы метод transform получал на вход pd.Dataframe, а возвращал np.array.\n",
    "\n",
    "3. В sklearn есть классы, от которых можно отнаследоваться, чтобы сделать класс с [fit-predict](https://scikit-learn.org/stable/modules/generated/sklearn.base.RegressorMixin.html#sklearn.base.RegressorMixin) или [fit-transform](https://scikit-learn.org/stable/modules/generated/sklearn.base.TransformerMixin.html) интерфейсом. Это очень полезно, т к позволит вам в дальнейшем пользоваться методами [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) и подобными. В этом пункте отнаследуйтесь от второго.\n",
    "\n",
    "4. У метода __init__ должен быть параметр ```needed_columns=None```. Туда передается список колонок, которые нужно взять из датафрейме. Делать это надо в ```fit``` и ```transform```. В случае если если он равен None, то класс оставляет все колонки из исходного набора данных.\n",
    "\n",
    "5. Обратите внимание, что достаточно реализовать `fit` и `transform`, а метод `fit_transform` из них слепит родительский класс.\n",
    "\n",
    "**Готовый препроцессор вам нужно будет сдать в Контест**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class BaseDataPreprocessor(TransformerMixin):\n",
    "    def __init__(self, needed_columns: Optional[List[str]]=None):\n",
    "        \"\"\"\n",
    "        :param needed_columns: if not None select these columns from the dataframe\n",
    "        \"\"\"\n",
    "        # self.scaler = ...\n",
    "        pass\n",
    "        self.needed_columns = needed_columns\n",
    "        self.scaler = StandardScaler()\n",
    "\n",
    "\n",
    "    def fit(self, data, *args):\n",
    "        \"\"\"\n",
    "        Prepares the class for future transformations\n",
    "        :param data: pd.DataFrame with all available columns\n",
    "        :return: self\n",
    "        \"\"\"\n",
    "        # Your code here\n",
    "        if self.needed_columns is not None:\n",
    "            selected_data = data[self.needed_columns]\n",
    "        else:\n",
    "            selected_data = data\n",
    "        \n",
    "        selected_data = selected_data.select_dtypes(include=['int', 'float'])\n",
    "        self.feature_columns = selected_data.columns.tolist()\n",
    "        self.scaler.fit(selected_data)\n",
    "        return self\n",
    "        \n",
    "\n",
    "    def transform(self, data: pd.DataFrame) -> np.array:\n",
    "        \"\"\"\n",
    "        Transforms features so that they can be fed into the regressors\n",
    "        :param data: pd.DataFrame with all available columns\n",
    "        :return: np.array with preprocessed features\n",
    "        \"\"\"\n",
    "        # Your code here\n",
    "        selected_data = data[self.feature_columns]\n",
    "        transformed_data = self.scaler.transform(selected_data)\n",
    "        return transformed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. (1 балл)** Сдайте вашу реализацию в Контест, задача «Простая предобработка»."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "preprocessor = BaseDataPreprocessor(needed_columns=continuous_columns)\n",
    "\n",
    "X_train = preprocessor.fit_transform(data_train)\n",
    "X_test = preprocessor.transform(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Умная предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь давайте попробуем сделать что-нибудь поинтереснее. Для того, чтобы будущие модели регрессии работали хорошо, они должны обучаться и предсказывать на информативных фичах. Зачастую оказывается гораздо продуктивнее потратить какое-то время на изучение предметной области и придумывание хороших фичей (feature engineering), нежели жадно перебирать все известные методы машинного обучения.\n",
    "В этом пункте попробуйте придумать новых фичей и написать новый класс предобработки данных, который их добавляет (а, возможно, и убирает ещё какие-то старые).\n",
    "\n",
    "В конце этого пункта в раскрывашке перечислены наши идеи относительно того, что можно было добавить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class SmartDataPreprocessor(TransformerMixin):\n",
    "    def __init__(self, needed_columns: Optional[List[str]] = None):\n",
    "        self.needed_columns = needed_columns\n",
    "        self.scaler = StandardScaler()\n",
    "        self.feature_columns = None\n",
    "        self.city_center_lat = 42.0308\n",
    "        self.city_center_lon = -93.6319\n",
    "        self.lot_frontage_median = None\n",
    "        \n",
    "    def fit(self, data, *args):\n",
    "        if self.needed_columns is not None:\n",
    "            selected_data = data[self.needed_columns].copy()\n",
    "        else:\n",
    "            selected_data = data.copy()\n",
    "        if 'Lot_Frontage' in selected_data.columns:\n",
    "            non_zero_frontage = selected_data['Lot_Frontage'][selected_data['Lot_Frontage'] > 0]\n",
    "            self.lot_frontage_median = non_zero_frontage.median()\n",
    "        selected_data = self._create_features(selected_data)\n",
    "        selected_data = selected_data.select_dtypes(include=['int64', 'float64'])\n",
    "        self.feature_columns = selected_data.columns.tolist()\n",
    "        self.scaler.fit(selected_data)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, data: pd.DataFrame) -> np.array:\n",
    "        if self.needed_columns is not None:\n",
    "            selected_data = data[self.needed_columns].copy()\n",
    "        else:\n",
    "            selected_data = data.copy()\n",
    "        selected_data = self._create_features(selected_data)\n",
    "        selected_data = selected_data[self.feature_columns]\n",
    "        transformed_data = self.scaler.transform(selected_data)\n",
    "        return transformed_data\n",
    "    \n",
    "    def _create_features(self, data: pd.DataFrame) -> pd.DataFrame:\n",
    "        data = data.copy()\n",
    "        if 'Lot_Frontage' in data.columns and self.lot_frontage_median is not None:\n",
    "            data['Lot_Frontage'] = data['Lot_Frontage'].replace(0, self.lot_frontage_median)\n",
    "        if 'Latitude' in data.columns and 'Longitude' in data.columns:\n",
    "            data['Distance_to_Center'] = np.sqrt(\n",
    "                (data['Latitude'] - self.city_center_lat) ** 2 + \n",
    "                (data['Longitude'] - self.city_center_lon) ** 2\n",
    "            )\n",
    "        area_features = []\n",
    "        if 'Gr_Liv_Area' in data.columns:\n",
    "            area_features.append('Gr_Liv_Area')\n",
    "        if 'Total_Bsmt_SF' in data.columns:\n",
    "            area_features.append('Total_Bsmt_SF')\n",
    "        if 'Garage_Area' in data.columns:\n",
    "            area_features.append('Garage_Area')\n",
    "        if area_features:\n",
    "            data['Total_SF'] = data[area_features].sum(axis=1)\n",
    "        if 'Year_Built' in data.columns:\n",
    "            data['House_Age'] = 2024 - data['Year_Built']\n",
    "        if 'Year_Remod_Add' in data.columns:\n",
    "            data['Remodel_Age'] = 2024 - data['Year_Remod_Add']\n",
    "        bathroom_features = []\n",
    "        if 'Full_Bath' in data.columns:\n",
    "            bathroom_features.append(data['Full_Bath'])\n",
    "        if 'Half_Bath' in data.columns:\n",
    "            bathroom_features.append(data['Half_Bath'] * 0.5)\n",
    "        if 'Bsmt_Full_Bath' in data.columns:\n",
    "            bathroom_features.append(data['Bsmt_Full_Bath'])\n",
    "        if 'Bsmt_Half_Bath' in data.columns:\n",
    "            bathroom_features.append(data['Bsmt_Half_Bath'] * 0.5)\n",
    "        if bathroom_features:\n",
    "            data['Total_Bathrooms'] = sum(bathroom_features)\n",
    "        if 'TotRms_AbvGrd' in data.columns and 'Bedroom_AbvGr' in data.columns:\n",
    "            data['Total_Rooms'] = data['TotRms_AbvGrd'] + data['Bedroom_AbvGr']\n",
    "        if 'Lot_Area' in data.columns and 'TotRms_AbvGrd' in data.columns:\n",
    "            data['Lot_Area_per_Room'] = data['Lot_Area'] / (data['TotRms_AbvGrd'] + 1)\n",
    "        if 'Overall_Qual' in data.columns and 'Overall_Cond' in data.columns:\n",
    "            data['Quality_Condition_Product'] = data['Overall_Qual'] * data['Overall_Cond']\n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "preprocessor = SmartDataPreprocessor(needed_columns=continuous_columns)\n",
    "\n",
    "X_train = preprocessor.fit_transform(data_train)\n",
    "X_test = preprocessor.transform(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>Пара простых идей. Кликните, когда будете готовы</summary>\n",
    "\n",
    "Например в датасете есть координаты квартиры, которые по идее сами по себе мало чего дают нашему регрессору. С другой стороны, по ним можно оценить центр города (или просто найти его на карте) и использовать в качестве фичи расстояние до центра города, которое может естественным образом влиять на цену жилья.\n",
    "\n",
    "Ещё может быть полезным почистить пропуски. И тут есть хитрость. Если вы просто вызовете data.info(), то вам покажется, что пропусков нет, но они могут приходить под разными обличьями. Например, у 490 объектов параметр Lot_Frontage (площадь фасада) равен нулю. Неожиданно, правда? Возможно, мы хотим эти нулевые значения заменить чем-нибудь, скажем, медианой.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Линейная регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте получим базовое решение (бейзлайн), чтобы потом с ним можно было сравниваться.\n",
    "\n",
    "Обучите линейную регрессию на обучающей выборке (которую мы подвергли преобразованию BaseDataPreprocessor). В библиотеке Sklearn есть релизация [без регуляризации](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html?highlight=linear%20regression), [с L2-регуляризацией](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge) и [с L1-регуляризацией](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso).\n",
    "\n",
    "Начнём с обычной регрессии. Получите предсказания на тестовых данных и оцените на них качество модели. В качестве метрики оценки качества возьмите [средний модуль отклонения](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html) (mean absolute error, MAE). Как вам кажется, насколько хорошей вышла модель?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2541778675.6432114\n"
     ]
    }
   ],
   "source": [
    "## <YOUR CODE HERE>\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, Y_train)\n",
    "preds = lr.predict(X_test)\n",
    "mse = mean_squared_error(Y_test, preds)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь попробуйте L2-регуляризованную модель Ridge. Какие значения метрик она даёт?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2540431199.075652\n"
     ]
    }
   ],
   "source": [
    "## <YOUR CODE HERE>\n",
    "lr = Ridge()\n",
    "lr.fit(X_train, Y_train)\n",
    "preds = lr.predict(X_test)\n",
    "mse = mean_squared_error(Y_test, preds)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В целом, регуляризация редко портит модель, но важно правильно подобрать коэффициент регуляризации. Как именно — поговорим позже."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Выбор метрики"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Средний модуль ошибки (MAE) — в целом довольно хорошая метрика для задачи регрессии, потому что ее довольно легко проинтерпретировать. Но с ней есть одна проблема: ошибиться на $ 10\\:000 $ USD в предсказании цены квартиры стоимостью $ 100\\:000 $ USD страшнее чем допустить такую ошибку в предсказании цены жилья за $ 700\\:000 $ USD. Иными словами более показательной метрикой будет не абсолютная  ошибка $ e_i = |y_i - \\widehat{y_i}|$, а логарифм относительной ошибки $e_i = \\log \\frac{y_i}{\\widehat{y_i}} $. Также давайте обычное усреднение по всем примерам в тестовой выборке заменим на среднеквадратичное $ \\frac{1}{n} \\sum_{i=1}^{n} {e_i} \\longrightarrow \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n}{e_i^2}}$. Итоговая метрика получается равной:\n",
    "\n",
    "$$\n",
    "Metric = \\sqrt{\\frac{1}{N} \\sum_{i=1}^{n} \\left[\\log y_i - \\log \\widehat{y_i}\\right]^2}\n",
    "$$\n",
    "\n",
    "Логично? Да. Но возникает еще одна проблема. Логарифм нельзя брать от отрицательного числа. Бороться с этим можно двумя способами.\n",
    "- Случай когда отрицательное число затисалось в target-ax не очень разумен, т. к. цена на дом не может быть отрицательной. В этом случае стоит кинуть ошибку, чтобы пользователь этой функции еще раз перепроверил правильные ли таргеты он подает.\n",
    "- В целом, у нас нет гарантий того, что наша модель (например линейная) предсказывает только положительные числа. Брать логарифм от отрицательного числа не получится, но качество такой модели все еще надо оценить. Давайте все предсказания, которые меньше некоторого порога $ a_{min} $, заменять этим порогом (то есть $ \\widehat{y_i} := \\max(\\widehat{y_i}, a_{min}) $), после чего подавать их в метрику. Для прохождения тестов возьмите $ a_{min} = 1 $.\n",
    "\n",
    "**2. (1 балл) Реализуйте эту метрику и сдайте в контест**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def root_mean_squared_logarithmic_error(y_true, y_pred, a_min=1.):\n",
    "    # <Your code here>\n",
    "    if np.any(y_true < 0):\n",
    "        raise ValueError(\"vveli krivoye chislo\")\n",
    "    y_pred_clipped = np.maximum(y_pred, a_min)\n",
    "    return np.sqrt(np.mean(np.log(y_pred_clipped / y_true) ** 2))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE: 0.06529472899661405\n"
     ]
    }
   ],
   "source": [
    "# zatestim\n",
    "y_true = np.asarray([100, 200, 300])\n",
    "y_pred = np.asarray([110, 190, 310])\n",
    "\n",
    "result = root_mean_squared_logarithmic_error(y_true, y_pred)\n",
    "print(f\"RMSLE: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Логарифмирование таргета."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вообще идея с логарифмированием таргета довольно хороша для этой задачи. Давайте посмотрим на распределение обычных и логарифмированных таргетов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_target_distribution(Y_train, Y_test, ax, n_bins=20):\n",
    "    ax.hist(Y_train, bins=n_bins, label=\"train\", color=\"red\", alpha=0.3, density=True)\n",
    "    ax.hist(Y_test, bins=n_bins, label=\"test\", color=\"blue\", alpha=0.3, density=True)\n",
    "\n",
    "    ax.legend()\n",
    "    ax.set_xlabel(\"Value\")\n",
    "    ax.set_ylabel(\"Probability\")\n",
    "\n",
    "\n",
    "def plot_both_distributions(Y_train, Y_test):\n",
    "    fig, (ax0, ax1) = plt.subplots(ncols=2, nrows=1, figsize=(15, 6))\n",
    "\n",
    "    plot_target_distribution(Y_train, Y_test, ax=ax0)\n",
    "    ax0.set_title(\"Standard\")\n",
    "\n",
    "    plot_target_distribution(np.log(Y_train), np.log(Y_test), ax=ax1)\n",
    "    ax1.set_title(\"Logarithmic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_both_distributions(Y_train, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видите, если прологарифмировать таргеты, то их распределение станет более похоже на гауссовское. Интуиция подсказывает, что линейная регрессия с функцией потерь MSE должна лучше учиться на таких таргетах.\n",
    "\n",
    "Попробуйте написать класс, который во время обучения логарифмирует таргет, а во время предсказания — наоборот, экспоненциирует. После чего обучите оба метода на обучающих данных и сравните значения метрик MAE и MSLE на тесте."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что должно быть в этом классе:\n",
    "- Класс должен называться ```ExponentialLinearRegression```\n",
    "- Класс должен иметь такой же fit-predict интерфейс, как и было до этого. На вход он получает оригинальные X и Y, а уже внутри происходит логарифмирование или экспоненциирование.\n",
    "- Внутри этой модели будет работать [Ridge](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html). Хочется, чтобы этому классу можно было передавать аргументы инициализации с помощью *args и **kwargs\n",
    "- Чтобы потом этот класс можно было использовать в [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) в следующих пунктах, у него должны быть реализованы 5 методов\n",
    "    1. ```__init__(self, *args, **kwargs)``` &mdash; все полученные аргументы передаются дальше в Ridge.\n",
    "    2. ```fit(self, X, Y)``` &mdash; обучает класс, возвращает self.\n",
    "    3. ```predict(self, X)``` &mdash; делает предсказание.\n",
    "    4. ```get_params(deep=True)``` &mdash; возвращает dict с параметрами модели. Больше подробностей [здесь](https://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html)\n",
    "    5. ```set_params(**params)``` &mdash; передает нужные параметры в модель. Больше подробносте [здесь](https://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html)\n",
    "- Есть два подхода к тому как сделать все нужные методы:\n",
    "    - Отнаследоваться от класса Ridge и переопределить методы fit и predict, внутри вызывая super() от отцовского класса.\n",
    "    - Отнаследоваться от класса RegressorMixin и внутренним атрибутом класса сделать Ridge. Тогда все методы нужно будет писать руками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "import numpy as np\n",
    "from sklearn.base import RegressorMixin\n",
    "\n",
    "class ExponentialLinearRegression(RegressorMixin):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.model = Ridge(*args, **kwargs)\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        return self.model.fit(X, np.log(Y))\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.exp(self.model.predict(X))\n",
    "        pass\n",
    "\n",
    "    def get_params(self, *args, **kwargs):\n",
    "        return self.model.get_params(*args, **kwargs, deep=True)\n",
    "        pass\n",
    "\n",
    "    def set_params(self, *args, **kwargs):\n",
    "        return self.model.set_params(*args, **kwargs)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. (1 балл) Реализуйте этот класс и сдайте в контест**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE  : Classic : 23655.203384324694  Exponential : 26246.670332781105\n",
      "MSLE : Classic : 0.19467093536161573 Exponential : 0.21294165264694315\n"
     ]
    }
   ],
   "source": [
    "classic_regressor = Ridge()\n",
    "exponential_regressor = ExponentialLinearRegression()\n",
    "\n",
    "classic_regressor.fit(X_train, Y_train)\n",
    "exponential_regressor.fit(X_train, Y_train)\n",
    "\n",
    "classic_prediction = classic_regressor.predict(X_test)\n",
    "exponential_prediction = exponential_regressor.predict(X_test)\n",
    "\n",
    "print(f\"MAE  : Classic : {mean_absolute_error(Y_test, classic_prediction)}  Exponential : {mean_absolute_error(Y_test, exponential_prediction)}\")\n",
    "print(f\"MSLE : Classic : {root_mean_squared_logarithmic_error(Y_test, classic_prediction)} Exponential : {root_mean_squared_logarithmic_error(Y_test, exponential_prediction)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут представлю решение к задачке где тестово надо было засабмитить мае для объединенных данных. В общем-то, просто сконкатенируем датафреймы и укажем параметры кросс-валидации, указанные в контесте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(23225.187338678435)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import make_scorer, mean_absolute_error\n",
    "\n",
    "data_full = pd.concat([data_train, data_test], ignore_index=True)\n",
    "Y_full = np.concatenate([Y_train, Y_test])\n",
    "preprocessor = BaseDataPreprocessor(needed_columns=continuous_columns)\n",
    "X_full = preprocessor.fit_transform(data_full)\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "model = LinearRegression()\n",
    "mae = cross_val_score(model, X_full, Y_full, \n",
    "                           cv=cv, \n",
    "                           scoring=make_scorer(mean_absolute_error))\n",
    "\n",
    "mae.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Иногда получается так, что разные обученные вами модели приводят к улучшению одних метрик и ухудшению других. Это абсолютно нормально и этому не надо удивляться.\n",
    "\n",
    "Также зачастую случается так, что прирост по метрике не очень большой. И вы можете захотеть убедиться, что это реальное улучшение, а не просто случайная флуктуация. Для этого можно использовать подсчёт метрики про кросс-валидации, о которой мы поговорим позже в нашем курсе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Линейная модель своими руками\n",
    "\n",
    "В этом разделе вы напишете собственный класс линейной модели, чтобы лучше разобраться, как работает обучение с помощью SGD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Линейная модель делает предсказание по такой формуле:\n",
    "$$\n",
    "\\widehat{y}(x) = x^T \\widehat{\\theta}\n",
    "$$\n",
    "Здесь $\\widehat{\\theta}$ &mdash; обучаемые параметры, $x$ &mdash; вектор фичей данного примера.\n",
    "Оценка $\\widehat{\\theta}$ находятся из задачи минимизации лосс функции:\n",
    "\n",
    "$$\n",
    "F(\\theta) = \\frac{1}{n} \\sum_{i=1}^{n} \\left(Y_i - x_i^T \\theta\\right)^2 + \\lambda \\theta^T\\theta \\longrightarrow \\min_{\\theta \\in \\mathbb{R}^d}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эту задачу минимизации будем решать градиентным спуском. Для этого реализуем этот метод ввиде класса с методами fit-predict.\n",
    "Что в нем должно быть:\n",
    "1. Класс должен называться ```SGDLinearRegressor```\n",
    "2. Класс должен быть отнаследован от sklearn-овского класса [RegressorMixin](https://scikit-learn.org/stable/modules/generated/sklearn.base.RegressorMixin.html)\n",
    "3. Класс должен инициализироваться со следующими гиперпараметрами:\n",
    "\n",
    "    * ```lr``` — learning rate. Длина шага градиентного спуска\n",
    "\n",
    "    * ```regularization``` — коэффициент $\\lambda$ из формулы выше\n",
    "    \n",
    "    * ```delta_converged``` — устанавливает условие окончание обучение. В тот момент когда норма разности весов на соседних шагах градиентного спуска меньше чем ```delta_converged``` метод прекращает обновлять веса\n",
    "    \n",
    "    * ```max_steps``` — максимальное число шагов градиентного спуска\n",
    "    \n",
    "    * ```batch_size``` — размер батча\n",
    "\n",
    "4. Реализуйте **стохастический** градиентный спуск. На каждом шагу градиентного спуска должен формироваться батч размера ```batch_size``` из матрицы признаков. Это нужно для того чтобы метод быстрее сходился. Батч может выбираться случайно на каждом шаге градиентного спуска, либо каждую эпоху можно перемешивать трейн выборку и итерироваться батчами по ней."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Обратите внимание при реализации SGD на следующие моменты (частые ошибки):\n",
    "* не перепутайте, какие коэффициенты в SGD стоят при самой функции потерь, а какие — при регуляризационном члене\n",
    "* для остановки нужно сравнивать норму, а не ее квадрат\n",
    "* для правильного решения нужно не итерироваться по батчу,  а перемножать матрицы (иначе не зайдет по TL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import RegressorMixin\n",
    "\n",
    "class SGDLinearRegressor(RegressorMixin):\n",
    "    def __init__(self, lr=0.01, regularization=1., delta_converged=1e-2, max_steps=1000, batch_size=64):\n",
    "        self.lr = lr\n",
    "        self.regularization = regularization\n",
    "        self.delta_converged = delta_converged\n",
    "        self.max_steps = max_steps\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.W = None\n",
    "        self.b = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.W = np.random.randn(n_features) * 0.01\n",
    "        self.b = 0.0\n",
    "        for step in range(self.max_steps):\n",
    "            indices = np.random.choice(n_samples, min(self.batch_size, n_samples), replace=False)\n",
    "            X_batch = X[indices]\n",
    "            y_batch = y[indices]\n",
    "            y_pred = X_batch.dot(self.W) + self.b\n",
    "            error = y_pred - y_batch\n",
    "            grad_W = (2.0 / len(y_batch)) * X_batch.T.dot(error) + 2.0 * self.regularization * self.W\n",
    "            grad_b = (2.0 / len(y_batch)) * error.sum()\n",
    "            W_old = self.W.copy()\n",
    "            self.W -= self.lr * grad_W\n",
    "            self.b -= self.lr * grad_b\n",
    "            weight_diff_norm = np.linalg.norm(self.W - W_old)\n",
    "            if weight_diff_norm < self.delta_converged:\n",
    "                break  \n",
    "        return self\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        return X.dot(self.W) + self.b\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import RegressorMixin\n",
    "\n",
    "class SGDLinearRegressor(RegressorMixin):\n",
    "    def __init__(self, lr=0.01, regularization=1., delta_converged=1e-2, max_steps=1000, batch_size=64):\n",
    "        self.lr = lr\n",
    "        self.regularization = regularization\n",
    "        self.delta_converged = delta_converged\n",
    "        self.max_steps = max_steps\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.W = None\n",
    "        self.b = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        self.W = np.random.randn(n_features) * 0.01\n",
    "        self.b = 0.0\n",
    "\n",
    "        for step in range(self.max_steps):\n",
    "            indices = np.random.choice(n_samples, min(self.batch_size, n_samples), replace=False)\n",
    "            X_batch = X[indices]\n",
    "            y_batch = y[indices]\n",
    "            y_pred = X_batch.dot(self.W) + self.b\n",
    "            error = y_pred - y_batch\n",
    "            grad_W = (2.0 / len(y_batch)) * X_batch.T.dot(error) + 2.0 * self.regularization * self.W\n",
    "            grad_b = (2.0 / len(y_batch)) * error.sum()\n",
    "            self.W -= self.lr * grad_W\n",
    "            self.b -= self.lr * grad_b\n",
    "\n",
    "        return self\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        return X.dot(self.W) + self.b\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(586,) (586,)\n",
      "MAE :  25219.9355375076\n",
      "Mean log :  0.19224787579807784\n"
     ]
    }
   ],
   "source": [
    "# Check yourself\n",
    "\n",
    "model = SGDLinearRegressor()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "prediction = model.predict(X_test)\n",
    "print(Y_test.shape, prediction.shape)\n",
    "print(\"MAE : \", mean_absolute_error(Y_test, prediction))\n",
    "print(\"Mean log : \", root_mean_squared_logarithmic_error(Y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Категориальные признаки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В самом начале ноутбука мы отбросили категориальные фичи, хотя они могут помочь нам сделать модель лучше. Давайте же научимся ими пользоваться.\n",
    "\n",
    "Самый простой подход — это закодировать значения категориального признака числами, скажем, от $0$ до $C-1$, где $C$ — количество значений категориального признака. Иногда это может сработать, но для этого нужно, чтобы между значениями признака были определены отношения больше/меньше (такие признаки называются _ординальными_), причём соотношения между значениями должны быть более-менее линейными. В целом, не очень частая ситуация, поэтому так мы делать не будем.\n",
    "\n",
    "Вместо этого мы будем использовать OneHotEncoding. Пусть некоторая категориальная фича имеет $C$ уникальных значений. Давайте эту фичу закодируем в виде $C$ столбцов, каждый из которых соответствует некоторому уникальному значению категориальной фичи. Для каждого элемента выборки будем класть единичку в столбец, соответствующий этой фиче, и нолики в остальные.\n",
    "\n",
    "У этого метода есть недостаток. Если категориальная фича принимает слишком много значений, то вы нагенерируете много новых столбцов, каждый из которых будет содержать мало информации. Из-за них моделька может переобучиться.\n",
    "\n",
    "Этот метод имплементирован [здесь](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html). У него есть пара важных гиперпараметров, которые стоит упомянуть:\n",
    "- ```handle_unknown``` &mdash; управляет обработкой незнакомых категорий на этапе `transform`. Число уникальных значений (и число столбцов) настраивается на обучающей выборке, и при дальнейшем применении может появиться значение, которого ещё не было. Если указать ```handle_unknown=\"ignore\"```, все поля для такого объекта будут заполнены нулями.\n",
    "- ```drop``` &mdash; если делать one-hot-encoding так как это описано выше, то сумма всех столбцов, соответствующих значениям категориальной фичи, будет равна единичному вектору. А такой вектор уже есть (он соответствует свободному члену). То есть признаки становятся линейно зависимыми, и это сломает процесс обучения линейной модели. Поэтому есть смысл для каждой фичи отбрасывать одну из получившихся колонок (```drop=\"first\"```) или хотя бы делать это только для бинарных фичей (```drop=\"if_binary\"```)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом пункте вам надо еще раз предобработать данные, добавив в них часть категориальных фичей, закодированных OneHotEncoding-ом. После этого обучите классификатор заново и выбейте лучшую метрику на тестовой выборке. А именно, мы добавим фичи \"Overall_Qual\", \"Garage_Qual\", \"Sale_Condition\", \"MS_Zoning\". Используйте значение параметра handle_unknown=\"ignore\".\n",
    "\n",
    "*Замечание.* На практике в некоторых версиях scikit-learn есть проблема с совместимостью `handle_unknown=\"ignore\"` и `drop=\"first\"` одновременно, поэтому вторым можно пожертвовать.\n",
    "\n",
    "Класс будет наследоваться от BaseDataPreprocessor, так что в него можно будет передавать нужные для BaseDataPreprocessor параметры. Также это позволит не переписывать заново то, что происходит в базовом классе, а просто взывать к ним с помощью конструкции `super`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "interesting_columns = [\"Overall_Qual\", \"Garage_Qual\", \"Sale_Condition\", \"MS_Zoning\"]\n",
    "\n",
    "class OneHotPreprocessor(BaseDataPreprocessor):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(OneHotPreprocessor, self).__init__(**kwargs)\n",
    "        ## <YOUR CODE HERE>\n",
    "\n",
    "    def fit(self, data, *args):\n",
    "        ## <YOUR CODE HERE>\n",
    "\n",
    "    def transform(self, data):\n",
    "        ## <YOUR CODE HERE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.base import TransformerMixin\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Optional, List\n",
    "interesting_columns = [\"Overall_Qual\", \"Garage_Qual\", \"Sale_Condition\", \"MS_Zoning\"]\n",
    "\n",
    "class BaseDataPreprocessor(TransformerMixin):\n",
    "    def __init__(self, needed_columns: Optional[List[str]]=None):\n",
    "        self.needed_columns = needed_columns\n",
    "        self.scaler = StandardScaler()\n",
    "\n",
    "    def fit(self, data, *args):\n",
    "        if self.needed_columns is not None:\n",
    "            selected_data = data[self.needed_columns]\n",
    "        else:\n",
    "            selected_data = data\n",
    "        \n",
    "        selected_data = selected_data.select_dtypes(include=['int', 'float'])\n",
    "        self.feature_columns = selected_data.columns.tolist()\n",
    "        self.scaler.fit(selected_data)\n",
    "        return self\n",
    "\n",
    "    def transform(self, data: pd.DataFrame) -> np.array:\n",
    "        selected_data = data[self.feature_columns]\n",
    "        transformed_data = self.scaler.transform(selected_data)\n",
    "        return transformed_data\n",
    "\n",
    "\n",
    "class OneHotPreprocessor(BaseDataPreprocessor):\n",
    "    def __init__(self, categorical_columns=None, **kwargs):\n",
    "        super(OneHotPreprocessor, self).__init__(**kwargs)\n",
    "        self.categorical_columns = categorical_columns if categorical_columns else []\n",
    "        self.encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "\n",
    "    def fit(self, data, *args):\n",
    "        if self.needed_columns is not None:\n",
    "            selected_data = data[self.needed_columns].copy()\n",
    "        else:\n",
    "            selected_data = data.copy()\n",
    "        \n",
    "        continuous_data = selected_data.select_dtypes(include=['int', 'float'])\n",
    "        self.continuous_columns = continuous_data.columns.tolist()\n",
    "        \n",
    "        if self.categorical_columns:\n",
    "            categorical_data = data[self.categorical_columns]\n",
    "            self.encoder.fit(categorical_data)\n",
    "        \n",
    "        self.scaler.fit(continuous_data)\n",
    "        return self\n",
    "\n",
    "    def transform(self, data: pd.DataFrame) -> np.array:\n",
    "        continuous_data = data[self.continuous_columns]\n",
    "        continuous_transformed = self.scaler.transform(continuous_data)\n",
    "        \n",
    "        if self.categorical_columns:\n",
    "            categorical_data = data[self.categorical_columns]\n",
    "            categorical_transformed = self.encoder.transform(categorical_data)\n",
    "            return np.hstack([continuous_transformed, categorical_transformed])\n",
    "        else:\n",
    "            return continuous_transformed\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите модель с добавленными категориальными фичами. Получилось ли улучшить её качество?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Представьте ситуацию. Прошел месяц с того момента, как вы построили модель, а теперь вам надо дообучить её на новых данных и активно применять для предсказания. Если вы не позаботились об инфраструктуре, то вам придётся рыскать по всему ноутбуку в поисках того, как вы предобрабатывали данные, какую модель учили, обязательно что-нибудь забудете и будете очень страдать. Поэтому человечество придумало пайплайны, которые позволяют объединить предобработку данных и обучение модели в один класс — pipeline. Его можно писать самому, либо взять из sklearn ([link](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)).\n",
    "\n",
    "**7. Напишите пайплайн, объединяющий использованную нами базовую предобработку данных (BaseDataPreprocessor и OneHotPreprocessor), а также линейную регрессию с L2-регуляризацией, и сдайте его в Контест.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def make_ultimate_pipeline():\n",
    "    # <YOUR CODE HERE>\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ultimate_pipeline():\n",
    "    interesting_columns = [\"Overall_Qual\", \"Garage_Qual\", \"Sale_Condition\", \"MS_Zoning\"]\n",
    "    preprocessor = OneHotPreprocessor(\n",
    "        categorical_columns=interesting_columns,\n",
    "        needed_columns=None\n",
    "    )\n",
    "    \n",
    "    model = Ridge(alpha=1.0)\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', model)\n",
    "    ])\n",
    "    \n",
    "    return pipeline\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом пункте вы попробуете сделать что-то поинтереснее и загрузите плоды выших трудов в Контест.\n",
    "\n",
    "Попробуйте усовершенствовать предобработку данных, добавляя или выкидывая фичи, придумывая функции от признаков так, чтобы улучшить качество классификатора.\n",
    "\n",
    "Ещё несколько базовых идей о том, что можно было бы попробовать:\n",
    "\n",
    "- Постройте гистограммы значений признаков. Вы обнаружите, что некоторые из них почти всегда принимают одно и то же значение. Для начала их можно просто выкинуть.\n",
    "- Почистите выбросы. У некоторых объектов значения каких-то признаков могут сильно выбиваться, и это будет мешать регрессии обучиться. Вообще говоря, такие объекты можно выкидывать, но с текущей архитектурой пайплайна вам будет трудно это настроить. Так что вы можете пока заменять их на более разумные значения.\n",
    "- Мы добавили лишь несколько категориальных признаков, а на самом деле многие из них могут быть полезными.\n",
    "- Можно дискретизовать непрерывные фичи. Самый банальный пример: если непрерывная фича принимает всего несколько значений, её можно попробовать проинтерпретировать, как категориальную, и подать в one-hot энкодер. Но можно и как-то ещё разбивать по порогам.\n",
    "- Можно делать и более сложные преобразования. Например в датасете есть координаты квартиры, которые по идее сами по себе мало чего дают нашему регрессору. С другой стороны, по ним можно оценить центр города (или просто найти его на карте) и использовать в качестве фичи расстояние до центра города, которое может естественным образом влиять на цену жилья.\n",
    "- Не забывайте настраивать коэффициент регуляризации: для разных датасетов оптимальное значение будет разным.\n",
    "\n",
    "**В контест вам нужно будет сдать свой класс модели**. Он будет обучаться и тестироваться на новом и неизвестном вам разбиении датасета на трейн и тест по метрике `root_mean_squared_logarithmic_error`. За значение метрики 0.185 вы получите 1 балл (метрика будет округляться до трёх знаков после запятой). Для этого должно быть достаточно нормально написать OneHotPreprocessor и использовать ExponentialLinearRegression с правильно подобранным коэффициентом регуляризации. Если вам удалось получить метрику меньше, то вы получите\n",
    "\n",
    "`1 + min(1, (0.19 - x) / (0.19 - 0.15))`\n",
    "\n",
    "балла.\n",
    "\n",
    "В контесте будет специально проверено, что вы сдаёте именно `Pipeline`.\n",
    "\n",
    "Не забывайте, что вместе с пайплайном вам нужно отправить и все самописные классы, которые в нём участвуют.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE :  18303.66640040059\n",
      "Mean log :  0.15713545940502183\n"
     ]
    }
   ],
   "source": [
    "pipeline = make_ultimate_pipeline()\n",
    "pipeline.fit(data_train, Y_train)\n",
    "Y_pred = pipeline.predict(data_test)\n",
    "print(\"MAE : \", mean_absolute_error(Y_test, Y_pred))\n",
    "print(\"Mean log : \", root_mean_squared_logarithmic_error(Y_test, Y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
